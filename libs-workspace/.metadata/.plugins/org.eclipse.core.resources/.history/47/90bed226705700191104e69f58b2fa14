package com.bit;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.SequenceFile;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;


//WordCount와 달리 기본 제공 Mapper,Reducer 활용
//hadoop jar ... com.bit.StringSort ...
public class StringSort {
   public static void main(String[] args) throws Exception {
      Configuration config = new Configuration();
      Job job = Job.getInstance(config, "StringSort");
      job.setJarByClass(StringSort.class);
      
      // 기본 Mapper, Reducer를 설정
      job.setMapperClass(Mapper.class);
      job.setReducerClass(Reducer.class);
      
      // Map, Reduce의 출력 Key,Value 설정
      job.setMapOutputKeyClass(Text.class);
      job.setMapOutputValueClass(Text.class);
      job.setOutputKeyClass(Text.class);
      job.setOutputValueClass(Text.class);
      
      // Reduce의 개수 설정
      job.setNumReduceTasks(1); // 1개
      
      job.setInputFormatClass(KeyValueTextInputFormat.class);
      job.setOutputFormatClass(SequenceFileOutputFormat.class);
      
      // 입출력 경로 설정
      FileInputFormat.addInputPath(job, new Path(args[0]));
      SequenceFileOutputFormat.setOutputPath(job, new Path(args[1]));
      // Sequence Format (사이즈 감소)
      
      SequenceFileOutputFormat.setOutputCompressionType(job, SequenceFile.CompressionType.BLOCK);
      
      job.waitForCompletion(true);
   }

}